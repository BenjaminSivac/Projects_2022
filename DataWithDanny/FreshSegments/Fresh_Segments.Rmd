---
title: "Data With Danny: Fresh Segments"
author: "Benjamin Sivac"
date: "`r Sys.Date()`"
output: 
  rmarkdown::github_document
---
```{r, include=FALSE}
hook_output <- knitr::knit_hooks$get("output")
```

```{r Loading packages, message=FALSE, warning=FALSE, include=FALSE}
library(DBI)
library(odbc)
library(tidyverse)
library(datamodelr) # ER diagram
```


```{r, include=FALSE}
con <- DBI::dbConnect(odbc::odbc(), 
                      Driver = "SQL Server", 
                      Server = "localhost\\SQLEXPRESS", 
                      Database = "datawdanny2", 
                      Trusted_Connection = "True")
```

## Introduction 

Danny created Fresh Segments, a digital marketing agency that helps other businesses analyse trends in online ad click behaviour for their unique customer base.

Clients share their customer lists with the Fresh Segments team who then aggregate interest metrics and generate a single dataset worth of metrics for further analysis.

In particular - the composition and rankings for different interests are provided for each client showing the proportion of their customer list who interacted with online assets related to each interest for each month.

Danny has asked for your assistance to analyse aggregated metrics for an example client and provide some high level insights about the customer list and their interests.

## Available Data
For this case study there is a total of 2 datasets which you will need to use to solve the questions.

### Interest Metrics
This table contains information about aggregated interest metrics for a specific major client of Fresh Segments which makes up a large proportion of their customer base.

Each record in this table represents the performance of a specific interest_id based on the client’s customer base interest measured through clicks and interactions with specific targeted advertising content.

```{sql,echo=FALSE, connection=con}
SELECT *
FROM
  dbo.interest_metrics
```
For example for the first row, in July 2018, the composition metric is 11.89, meaning that 11.89% of the client’s customer list interacted with the interest interest_id = 32486 - we can link interest_id to a separate mapping table to find the segment name called “Vacation Rental Accommodation Researchers”

The index_value is 6.19, means that the composition value is 6.19x the average composition value for all Fresh Segments clients’ customer for this particular interest in the month of July 2018.

The ranking and percentage_ranking relates to the order of index_value records in each month year.

### Interest Map
This mapping table links the interest_id with their relevant interest information. You will need to join this table onto the previous interest_details table to obtain the interest_name as well as any details about the summary information.

```{sql, echo=FALSE, connection=con}
SELECT id, interest_name, interest_summary
FROM dbo.interest_map
```

# Case Study Questions
The following questions can be considered key business questions that are required to be answered for the Fresh Segments team.

Most questions can be answered using a single query however some questions are more open ended and require additional thought and not just a coded solution!

## A. Data Exploration and Cleansing

**A.1 Update the interest_metrics table by modifying the month_year column to be a date data type with the start of the month**

MSQL can't convert MM-YYYY format to date, so we'll instead create another column with DATE type, set new column equal to old values + another date stamp, remove old one, and finally rename the new column to month_year
```{sql, connection=con, eval=FALSE}
ALTER TABLE interest_metrics 
ADD month DATE;

UPDATE interest_metrics
SET month='01-' + [month_year] -- Only way I can add another date element, but the server thinks it is month.

UPDATE interest_metrics
SET month= FORMAT(month,'dd/MM/yyyy') -- Now it's in a correct format !

ALTER TABLE interest_metrics
DROP COLUMN month_year -- drop old column

exec sp_RENAME 'interest_metrics.month','month_year', 'COLUMN' -- rename our new column.
-- Annoying but what can you do...
```
***


**A.2 What is count of records in the fresh_segments.interest_metrics for each month_year value sorted in chronological order (earliest to latest) with the null values appearing first?**

```{sql, connection=con}
SELECT 
	month_year,
	COUNT(month_year) AS count_records
FROM
	interest_metrics
GROUP BY month_year
ORDER BY month_year
```
***

**A.3 What do you think we should do with these null values in the fresh_segments.interest_metrics**

```{sql, connection=con}
SELECT 
	*
FROM
	interest_metrics
ORDER BY month_year
```
All but 1 record with month_year as NULL has NULL values in interest_id. 
It'd be hard to identify clients without the id and time stamp, 
so we either drop or filter em out.

***

**A.4 How many interest_id values exist in the fresh_segments.interest_metrics table but not in the fresh_segments.interest_map table? What about the other way around?**

```{sql, connection=con}
SELECT
	COUNT(DISTINCT(interest_id)) AS interest_id_count,
	COUNT(DISTINCT(id)) AS id_count,
	SUM(CASE WHEN interest_id IS NULL THEN 1 END) AS not_in_map,
	SUM(CASE WHEN id IS NULL THEN 1 END) AS not_in_metric
FROM
	interest_metrics metrics
	RIGHT OUTER JOIN 
		interest_map map
		ON
			metrics.interest_id = map.id
```
There are 7 id values in interest_map that are not in interest_metrics, and 0 interest id values in interest_metrics that are not in interest_map.

***

**A.5 Summarise the id values in the fresh_segments.interest_map by its total record count in this table**

```{sql, connection = con}
SELECT
  COUNT(*) AS total_record_count
FROM
  interest_map
```
An unusually simple question...

***

**A.6 What sort of table join should we perform for our analysis and why? Check your logic by checking the rows where interest_id = 21246 in your joined output and include all columns from fresh_segments.interest_metrics and all columns from fresh_segments.interest_map except from the id column.**

To query all columns from both tables, while filtering for only id 21245, we can use INNER JOIN.
```{sql, connection = con}
SELECT _month, _year, interest_id, composition, index_value, ranking, percentile_ranking, month_year,
      interest_name, interest_summary
FROM interest_metrics metrics
INNER JOIN interest_map map
  ON metrics.interest_id = map.id
WHERE interest_id = 21246
```
Note that we get one record with NULL time stamps values, which wont neccesarily disturb our analysis unless we are specifically interested in said time stamps. Also, there's no convenient way to exclude one column, like id, from a * query. So I had to list each column name.

***

**A.7 Are there any records in your joined table where the month_year value is before the created_at value from the fresh_segments.interest_map table? Do you think these values are valid and why?**

```{sql, connection=con}
SELECT 
	COUNT(*)
FROM interest_metrics me
INNER JOIN interest_map ma
  ON me.interest_id = ma.id
WHERE MONTH(month_year) < MONTH(created_at)
```
We'll cross reference with the _month column and find out if we get the same number of observations.
```{sql, connection=con}
SELECT 
	COUNT(*)
FROM interest_metrics me
INNER JOIN interest_map ma
  ON me.interest_id = ma.id
WHERE _month < MONTH(created_at)
```
Confirmed to also be 4972 observations. I assume that the interest_map table was created at a later date which is what the created_at column is referring to. It would then not share any connections to the other time stamp columns, and is therefore valid and accurate. 

***

## B. Interest Analysis

**B.1 Which interests have been present in all month_year dates in our dataset?**

```{sql, connection = con}
WITH cte_total_months AS(
	SELECT 
		interest_id,
		COUNT(DISTINCT month_year) AS total_months 
	FROM
		interest_metrics
	WHERE month_year IS NOT NULL
	GROUP BY interest_id
)

SELECT 
	COUNT(DISTINCT interest_id) AS countd_interests,
	total_months
FROM
	cte_total_months
WHERE total_months = 14
GROUP BY total_months;
```
***

**B.2 Using this same total_months measure - calculate the cumulative percentage of all records starting at 14 months - which total_months value passes the 90% cumulative percentage value?**
```{sql, connection = con}
WITH cte_total_months AS(
	SELECT 
		interest_id,
		COUNT(DISTINCT month_year) AS total_months 
	FROM
		interest_metrics
	WHERE month_year IS NOT NULL
	GROUP BY interest_id
),
cte_countd_interests AS(
	SELECT
		COUNT(DISTINCT interest_id) as countd_interests,
		total_months
	FROM
		cte_total_months
	GROUP BY total_months
)

SELECT 
	total_months,
	countd_interests,
	100 * SUM(countd_interests) OVER (ORDER BY total_months DESC) /
      SUM(countd_interests) OVER () AS cumulative_percentage -- running sum of all interests, by total_months, divided by sum of all interests.
FROM
	cte_countd_interests;
```
Cumulative percentaget value passes 90% by 6 months and above. Rest have relatively low clicks and interactions. 

***

**B.3 If we were to remove all interest_id values which are lower than the total_months value we found in the previous question - how many total data points would we be removing?**

```{sql, connection = con}
WITH cte_total_months AS(
	SELECT 
		interest_id,
		COUNT(DISTINCT month_year) AS total_months 
	FROM
		interest_metrics
	WHERE month_year IS NOT NULL
	GROUP BY interest_id
),
cte_low_months AS(
	SELECT
		COUNT(DISTINCT interest_id) as countd_interests,
		total_months
	FROM
		cte_total_months
	GROUP BY total_months
	HAVING total_months < 6
)
SELECT
	SUM(countd_interests) AS nbr_data_pts
FROM 
	cte_low_months;
```
110 observations have less than 6 months of interests and is expected to be removed.

***

**B.4 Does this decision make sense to remove these data points from a business perspective? Use an example where there are all 14 months present to a removed interest example for your arguments - think about what it means to have less months present from a segment perspective.** 

No they should be investigated and improved upon to garner more clicks and interactions. 
The more segments there are, the harder it is to reach these arbitrary thresholds. 
Removing an interest with 14 months present vs one with 1 present months has the same impact on the cumulative percentage.

***

**B.5 After removing these interests - how many unique interests are there for each month?**
We first count distinct months per interest_id, filter by number of months, and then summarise each unique interest by month. 
```{sql, connection = con}
WITH cte_total_months AS(
	SELECT 
		DISTINCT interest_id AS unique_interests,
		COUNT(DISTINCT month_year) AS total_months
	FROM
		interest_metrics
	WHERE month_year IS NOT NULL
	GROUP BY interest_id
),
cte_filter AS (	
	SELECT
		COUNT(unique_interests) as nbr_unique_interests,
		metrics.month_year,
		total_months
	FROM
		cte_total_months cte
		INNER JOIN
			interest_metrics metrics
		ON
			cte.unique_interests = metrics.interest_id		
	GROUP BY total_months, metrics.month_year
	HAVING total_months > 5
)
SELECT
	SUM(nbr_unique_interests) AS count_unique_interests,
	month_year
FROM
	cte_filter
GROUP BY month_year;
```

***


## C. Segment Analysis
 
**C.1 Using our filtered dataset by removing the interests with less than 6 months worth of data, which are the top 10 and bottom 10 interests which have the largest composition values in any month_year? Only use the maximum composition value for each interest but you must keep the corresponding month_year**

Note that I was not able to join the tables for each question below this analysis for querying interest_name, as it resulted in an “Invalid Descriptor Index” error when I wrote it in Rmarkdown.  

```{sql, connection = con}
WITH cte_filtered AS(
	SELECT
		DISTINCT interest_id AS unique_interest_id,
		MAX(composition) AS max_comp
	FROM
		interest_metrics
	WHERE month_year IS NOT NULL
	GROUP BY interest_id
	HAVING COUNT(DISTINCT month_year)>5
),
cte_t1 AS(
SELECT
		unique_interest_id,
		max_comp,
		FORMAT(month_year, 'MMM yyyy') AS month_year
	FROM
		cte_filtered cte
	INNER JOIN
		interest_metrics me
		ON	cte.unique_interest_id = me.interest_id AND cte.max_comp=me.composition
)
		
SELECT TOP 10
  *
FROM
  cte_t1
ORDER BY max_comp DESC
```

```{sql eval=FALSE, connection=con}
SELECT TOP 10
  *
FROM
  cte_t1
ORDER BY max_comp
```

```{sql echo=FALSE, connection=con}
WITH cte_filtered AS(
	SELECT
		DISTINCT interest_id AS unique_interest_id,
		MAX(composition) AS max_comp
	FROM
		interest_metrics
	WHERE month_year IS NOT NULL
	GROUP BY interest_id
	HAVING COUNT(DISTINCT month_year)>5
),
cte_t1 AS(
SELECT
		unique_interest_id,
		max_comp,
		FORMAT(month_year, 'MMM yyyy') AS month_year
	FROM
		cte_filtered cte
	INNER JOIN
		interest_metrics me
		ON	cte.unique_interest_id = me.interest_id AND cte.max_comp=me.composition
)
		
SELECT TOP 10
  *
FROM
  cte_t1
ORDER BY max_comp
```


***

**C.2 Which 5 interests had the lowest average ranking value?**
```{sql, connection=con}

SELECT TOP 5
	interest_id,
	AVG(ranking) AS avg_rank
FROM
	interest_metrics 
GROUP BY interest_id
ORDER BY AVG(ranking) DESC

```
***

**C.3 Which 5 interests had the largest standard deviation in their percentile_ranking value?**
```{sql, connection=con}
WITH cte_sd AS(
	SELECT TOP 5
		interest_id,
		STDEV(percentile_ranking) AS sd_centile_rank
	FROM
		interest_metrics 
	GROUP BY interest_id
	ORDER BY STDEV(percentile_ranking) DESC
)
SELECT
	interest_id,
	ROUND(sd_centile_rank,2) AS sd_centile_rank
FROM
	cte_sd sd
ORDER BY sd_centile_rank DESC;
```
***

**C.4 For the 5 interests found in the previous question - what was minimum and maximum percentile_ranking values for each interest and its corresponding year_month value? Can you describe what is happening for these 5 interests?**
```{sql, connection=con}
WITH cte_sd AS(
	SELECT TOP 5
		interest_id,
		MAX(percentile_ranking) AS max_centile,
		MIN(percentile_ranking) AS min_centile
	FROM
		interest_metrics 
	GROUP BY interest_id
	ORDER BY STDEV(percentile_ranking) DESC
),
cte_max_month AS(
	SELECT
		sd.interest_id as interest_id,
		max_centile,
		min_centile,
		month_year AS max_month_year
	FROM
		cte_sd sd
	INNER JOIN
		interest_metrics t1
		ON	sd.interest_id = t1.interest_id AND max_centile=t1.percentile_ranking
)
SELECT
	mm.interest_id,
	max_centile,
	FORMAT(max_month_year, 'MMM yyyy') AS max_month_year,
	min_centile,
	FORMAT(t2.month_year, 'MMM yyyy') AS min_month_year
FROM
	cte_max_month mm
INNER JOIN
	interest_metrics t2
	ON	mm.interest_id = t2.interest_id AND min_centile=t2.percentile_ranking
```

Probably not the most efficient solution for retrieving an output with months for each max and min value on the same row.
I'd bet that there is an obviously better format, perhaps by doing it in a long format and not minding any null values, 
but I thought this would look somewhat nicer.

***

**C.5 How would you describe our customers in this segment based off their composition and ranking values? What sort of products or services should we show to these customers and what should we avoid?**

The interest id's are in order: 'Tv Junkies', 'Techies', 'Entertainment Industry Decision Makers', 'Android Fans', and 'Blackbuster Movie Fans'.

As for my observations; There's a High variation by seasons, and a big reliance on new products and shows to engage them.
I believe new flagship phones do release in July, and hype for seasonal tv shows peak
for their finales in late july, resulting in a following drought before the next season begins.

## D. Index Analysis

**D.1 What is the top 10 interests by the average composition for each month?**

```{sql, connection=con}
WITH cte_rn AS(
	SELECT
		interest_id,
		ROUND(composition / index_value, 2) AS avg_composition,
		ROW_NUMBER() OVER(PARTITION BY month_year ORDER BY ROUND(composition / index_value, 2) DESC) AS rank,
		month_year
	FROM
		interest_metrics
)
SELECT
	interest_id,
	avg_composition,
	FORMAT(month_year, 'MMM yyyy') AS month_year
FROM
	cte_rn rn
WHERE rank < 11 AND interest_id IS NOT NULL
ORDER BY month_year, rank
```
***

**D.2. For all of these top 10 interests - which interest appears the most often?**
```{sql, connection=con}
WITH cte_rn AS(
	SELECT
		interest_id,
		ROUND(composition / index_value, 2) AS avg_composition,
		ROW_NUMBER() OVER(PARTITION BY month_year ORDER BY ROUND(composition / index_value, 2) DESC) AS rank,
		month_year
	FROM
		interest_metrics
)
SELECT
	interest_id,
	COUNT(interest_id) AS count
FROM
	cte_rn rn
WHERE rank < 11 AND interest_id IS NOT NULL
GROUP BY interest_id
ORDER BY count DESC
```
***

**D.3 What is the average of the average composition for the top 10 interests for each month?**
```{sql, connection=con}
WITH cte_rn AS(
	SELECT
		interest_id,
		ROUND(composition / index_value, 2) AS avg_composition,
		ROW_NUMBER() OVER(PARTITION BY month_year ORDER BY ROUND(composition / index_value, 2) DESC) AS rank,
		month_year
	FROM
		interest_metrics
)
SELECT
	DISTINCT FORMAT(month_year, 'MMM yyyy') AS month_year,
	AVG(avg_composition) OVER(PARTITION BY month_year) AS avg_avg_comp
FROM
	cte_rn rn
WHERE rank < 11 AND interest_id IS NOT NULL
ORDER BY month_year DESC
```
***

**D.4 What is the 3 month rolling average of the max average composition value from September 2018 to August 2019 and include the previous top ranking interests in the same output shown below.**
```{sql, connection=con}
WITH cte_rn AS(
	SELECT
		interest_id,
		ROUND(composition / index_value, 2) AS avg_composition,
		ROW_NUMBER() OVER(PARTITION BY month_year ORDER BY ROUND(composition / index_value, 2) DESC) AS rank,
		month_year
	FROM
		interest_metrics
	WHERE month_year BETWEEN '2018-07-01' AND '2019-08-01'
),
cte_max AS(
	SELECT
		DISTINCT CAST(month_year AS DATE) AS month_year,
		MAX(avg_composition) OVER(PARTITION BY month_year) AS max_avg_comp
	FROM
		cte_rn rn
),
cte_lags AS(
	SELECT
		month_year,
		max_avg_comp,
		LAG(max_avg_comp, 1, 0) OVER (ORDER BY CAST(month_year AS DATE)) AS _1_month_ago,
		LAG(max_avg_comp, 2, 0) OVER (ORDER BY CAST(month_year AS DATE)) AS _2_months_ago
	FROM
		cte_max max
)
SELECT
	month_year,
	max_avg_comp,
	ROUND((max_avg_comp + _1_month_ago + _2_months_ago)/3,2) AS _3_month_moving_avg,
	_1_month_ago,
	_2_months_ago
FROM
	cte_lags lags
WHERE month_year >= '2018-09-01'
```

I dislike hardcoding the average but I didn't find another solution since the AVG() function doesn't work across multiple columns. I have yet to add interest_name and concatenate it with the lagged values, it'll likely require 1-2 more CTEs to pull off.










